{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9d9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfd8795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dhananjay\\\\3D Objects\\\\imarticus PGDA\\\\Machine learning\\\\Supervised Learning\\\\KNN\\\\Market Positioning of Mobile'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff52c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  clock_speed  fc  int_memory  m_dep  mobile_wt  n_cores  \\\n",
       "0               842          2.2   1           7    0.6        188        2   \n",
       "1              1021          0.5   0          53    0.7        136        3   \n",
       "2               563          0.5   2          41    0.9        145        5   \n",
       "3               615          2.5   0          10    0.8        131        6   \n",
       "4              1821          1.2  13          44    0.6        141        2   \n",
       "...             ...          ...  ..         ...    ...        ...      ...   \n",
       "1995            794          0.5   0           2    0.8        106        6   \n",
       "1996           1965          2.6   0          39    0.2        187        4   \n",
       "1997           1911          0.9   1          36    0.7        108        8   \n",
       "1998           1512          0.9   4          46    0.1        145        5   \n",
       "1999            510          2.0   5          45    0.9        168        6   \n",
       "\n",
       "      pc  px_height  px_width   ram  sc_h  sc_w  talk_time  price_range  \n",
       "0      2         20       756  2549     9     7         19            1  \n",
       "1      6        905      1988  2631    17     3          7            2  \n",
       "2      6       1263      1716  2603    11     2          9            2  \n",
       "3      9       1216      1786  2769    16     8         11            2  \n",
       "4     14       1208      1212  1411     8     2         15            1  \n",
       "...   ..        ...       ...   ...   ...   ...        ...          ...  \n",
       "1995  14       1222      1890   668    13     4         19            0  \n",
       "1996   3        915      1965  2032    11    10         16            2  \n",
       "1997   3        868      1632  3057     9     1          5            3  \n",
       "1998   5        336       670   869    18    10         19            0  \n",
       "1999  16        483       754  3919    19     4          2            3  \n",
       "\n",
       "[2000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.read_csv('Mobile_data.csv')\n",
    "df =data.copy(deep=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76146a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>9.916500</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>6.064315</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power  clock_speed           fc   int_memory        m_dep  \\\n",
       "count    2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     1.522250     4.309500    32.046500     0.501750   \n",
       "std       439.418206     0.816004     4.341444    18.145715     0.288416   \n",
       "min       501.000000     0.500000     0.000000     2.000000     0.100000   \n",
       "25%       851.750000     0.700000     1.000000    16.000000     0.200000   \n",
       "50%      1226.000000     1.500000     3.000000    32.000000     0.500000   \n",
       "75%      1615.250000     2.200000     7.000000    48.000000     0.800000   \n",
       "max      1998.000000     3.000000    19.000000    64.000000     1.000000   \n",
       "\n",
       "         mobile_wt      n_cores           pc    px_height     px_width  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    140.249000     4.520500     9.916500   645.108000  1251.515500   \n",
       "std      35.399655     2.287837     6.064315   443.780811   432.199447   \n",
       "min      80.000000     1.000000     0.000000     0.000000   500.000000   \n",
       "25%     109.000000     3.000000     5.000000   282.750000   874.750000   \n",
       "50%     141.000000     4.000000    10.000000   564.000000  1247.000000   \n",
       "75%     170.000000     7.000000    15.000000   947.250000  1633.000000   \n",
       "max     200.000000     8.000000    20.000000  1960.000000  1998.000000   \n",
       "\n",
       "               ram         sc_h         sc_w    talk_time  price_range  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean   2124.213000    12.306500     5.767000    11.011000     1.500000  \n",
       "std    1084.732044     4.213245     4.356398     5.463955     1.118314  \n",
       "min     256.000000     5.000000     0.000000     2.000000     0.000000  \n",
       "25%    1207.500000     9.000000     2.000000     6.000000     0.750000  \n",
       "50%    2146.500000    12.000000     5.000000    11.000000     1.500000  \n",
       "75%    3064.500000    16.000000     9.000000    16.000000     2.250000  \n",
       "max    3998.000000    19.000000    18.000000    20.000000     3.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b4158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea1a72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=df.px_height,data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd8fea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.px_height)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab5b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481    0\n",
       "1933    0\n",
       "Name: px_height, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.px_height[df.px_height==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd4a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHANAN~1\\AppData\\Local\\Temp/ipykernel_11776/1931297500.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.px_height[df.px_height==0]=df.px_height.mean\n"
     ]
    }
   ],
   "source": [
    "df.px_height[df.px_height==0]=df.px_height.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3745e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHANAN~1\\AppData\\Local\\Temp/ipykernel_11776/1228802390.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.px_height[df.px_height==0]=np.nan\n"
     ]
    }
   ],
   "source": [
    "# or you can replace like this\n",
    "df.px_height[df.px_height==0]=np.nan\n",
    "df.px_height.fillna(df.px_height.mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2162b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    0\n",
       "clock_speed      0\n",
       "fc               0\n",
       "int_memory       0\n",
       "m_dep            0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "pc               0\n",
       "px_height        0\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "price_range      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02bee1",
   "metadata": {},
   "source": [
    "So many inconssistences in data of px_height,px_width,sc_w,sc_h so we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2367a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset=df.drop(['px_height','px_width','sc_w','sc_h'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3027293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>ram</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2549</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2631</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2603</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2769</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1411</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>668</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2032</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3057</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>869</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3919</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  clock_speed  fc  int_memory  m_dep  mobile_wt  n_cores  \\\n",
       "0               842          2.2   1           7    0.6        188        2   \n",
       "1              1021          0.5   0          53    0.7        136        3   \n",
       "2               563          0.5   2          41    0.9        145        5   \n",
       "3               615          2.5   0          10    0.8        131        6   \n",
       "4              1821          1.2  13          44    0.6        141        2   \n",
       "...             ...          ...  ..         ...    ...        ...      ...   \n",
       "1995            794          0.5   0           2    0.8        106        6   \n",
       "1996           1965          2.6   0          39    0.2        187        4   \n",
       "1997           1911          0.9   1          36    0.7        108        8   \n",
       "1998           1512          0.9   4          46    0.1        145        5   \n",
       "1999            510          2.0   5          45    0.9        168        6   \n",
       "\n",
       "      pc   ram  talk_time  price_range  \n",
       "0      2  2549         19            1  \n",
       "1      6  2631          7            2  \n",
       "2      6  2603          9            2  \n",
       "3      9  2769         11            2  \n",
       "4     14  1411         15            1  \n",
       "...   ..   ...        ...          ...  \n",
       "1995  14   668         19            0  \n",
       "1996   3  2032         16            2  \n",
       "1997   3  3057          5            3  \n",
       "1998   5   869         19            0  \n",
       "1999  16  3919          2            3  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81d274f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "1995    0\n",
       "1996    2\n",
       "1997    3\n",
       "1998    0\n",
       "1999    3\n",
       "Name: price_range, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "x=df_subset.iloc[:,1:-1]\n",
    "y=df_subset.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054efe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report as report\n",
    "from sklearn.metrics import confusion_matrix as matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06dfcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting\n",
    "sc=StandardScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5,weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c73edca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "x_train,x_test,y_train,y_test=split(x,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d1ddc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCaled DATA    \n",
    "x_train_sc=sc.fit_transform(x_train)\n",
    "# dataframe\n",
    "X_train_sc=pd.DataFrame(x_train_sc)\n",
    "\n",
    "\n",
    "x_test_sc=sc.transform(x_test)\n",
    "#dataframe\n",
    "X_test_sc=pd.DataFrame(x_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59355cd0",
   "metadata": {},
   "source": [
    "# KNN BASE Model SCALED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ed15f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 1, 'acc': [1.0, 0.54]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       384\n",
      "           1       1.00      1.00      1.00       374\n",
      "           2       1.00      1.00      1.00       365\n",
      "           3       1.00      1.00      1.00       377\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       116\n",
      "           1       0.40      0.42      0.41       126\n",
      "           2       0.45      0.48      0.46       135\n",
      "           3       0.70      0.65      0.67       123\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.55      0.54      0.55       500\n",
      "weighted avg       0.55      0.54      0.54       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[384   0   0   0]\n",
      " [  0 374   0   0]\n",
      " [  0   0 365   0]\n",
      " [  0   0   0 377]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[72 30 13  1]\n",
      " [29 53 35  9]\n",
      " [ 7 38 65 25]\n",
      " [ 1 10 32 80]]\n",
      "{'k': 3, 'acc': [0.7746666666666666, 0.516]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       384\n",
      "           1       0.67      0.69      0.68       374\n",
      "           2       0.77      0.65      0.70       365\n",
      "           3       0.89      0.85      0.87       377\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.78      0.77      0.77      1500\n",
      "weighted avg       0.78      0.77      0.77      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.61       116\n",
      "           1       0.34      0.42      0.38       126\n",
      "           2       0.47      0.33      0.39       135\n",
      "           3       0.73      0.67      0.70       123\n",
      "\n",
      "    accuracy                           0.52       500\n",
      "   macro avg       0.53      0.52      0.52       500\n",
      "weighted avg       0.52      0.52      0.51       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[348  33   3   0]\n",
      " [ 75 258  36   5]\n",
      " [ 24  69 237  35]\n",
      " [  2  24  32 319]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[78 32  6  0]\n",
      " [48 53 22  3]\n",
      " [11 52 45 27]\n",
      " [ 1 17 23 82]]\n",
      "{'k': 5, 'acc': [0.7486666666666667, 0.564]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.82       384\n",
      "           1       0.67      0.63      0.65       374\n",
      "           2       0.70      0.68      0.69       365\n",
      "           3       0.88      0.79      0.83       377\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.75      0.75      0.75      1500\n",
      "weighted avg       0.75      0.75      0.75      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69       116\n",
      "           1       0.42      0.48      0.45       126\n",
      "           2       0.52      0.42      0.47       135\n",
      "           3       0.71      0.63      0.67       123\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.57      0.57      0.57       500\n",
      "weighted avg       0.57      0.56      0.56       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[342  41   1   0]\n",
      " [ 99 237  36   2]\n",
      " [ 12  69 247  37]\n",
      " [  0   9  71 297]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[86 28  2  0]\n",
      " [45 61 17  3]\n",
      " [ 4 45 57 29]\n",
      " [ 0 12 33 78]]\n",
      "{'k': 7, 'acc': [0.7466666666666667, 0.552]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       384\n",
      "           1       0.70      0.61      0.65       374\n",
      "           2       0.66      0.68      0.67       365\n",
      "           3       0.86      0.79      0.82       377\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.75      0.75      0.74      1500\n",
      "weighted avg       0.75      0.75      0.74      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       116\n",
      "           1       0.41      0.45      0.43       126\n",
      "           2       0.49      0.41      0.45       135\n",
      "           3       0.72      0.67      0.69       123\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.56      0.56      0.56       500\n",
      "weighted avg       0.55      0.55      0.55       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[349  33   2   0]\n",
      " [ 87 227  53   7]\n",
      " [ 17  57 248  43]\n",
      " [  0   9  72 296]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[81 29  6  0]\n",
      " [44 57 22  3]\n",
      " [ 6 44 56 29]\n",
      " [ 0 10 31 82]]\n",
      "{'k': 9, 'acc': [0.7373333333333333, 0.568]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       384\n",
      "           1       0.69      0.61      0.65       374\n",
      "           2       0.66      0.63      0.64       365\n",
      "           3       0.84      0.79      0.81       377\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.73      0.74      0.73      1500\n",
      "weighted avg       0.74      0.74      0.73      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70       116\n",
      "           1       0.43      0.48      0.46       126\n",
      "           2       0.50      0.44      0.47       135\n",
      "           3       0.70      0.63      0.66       123\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.58      0.57      0.57       500\n",
      "weighted avg       0.57      0.57      0.57       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[349  33   2   0]\n",
      " [ 93 229  47   5]\n",
      " [ 21  62 229  53]\n",
      " [  0   9  69 299]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[86 29  1  0]\n",
      " [39 61 23  3]\n",
      " [ 3 42 60 30]\n",
      " [ 0 10 36 77]]\n",
      "{'k': 11, 'acc': [0.7253333333333334, 0.612]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83       384\n",
      "           1       0.67      0.58      0.62       374\n",
      "           2       0.63      0.65      0.64       365\n",
      "           3       0.82      0.77      0.79       377\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.72      0.72      0.72      1500\n",
      "weighted avg       0.72      0.73      0.72      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       116\n",
      "           1       0.47      0.50      0.48       126\n",
      "           2       0.55      0.51      0.53       135\n",
      "           3       0.77      0.70      0.74       123\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.62      0.62      0.62       500\n",
      "weighted avg       0.62      0.61      0.61       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[346  37   1   0]\n",
      " [ 94 217  57   6]\n",
      " [ 14  59 236  56]\n",
      " [  0  10  78 289]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[88 27  1  0]\n",
      " [36 63 25  2]\n",
      " [ 4 39 69 23]\n",
      " [ 0  6 31 86]]\n",
      "{'k': 13, 'acc': [0.7126666666666667, 0.608]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       384\n",
      "           1       0.65      0.57      0.60       374\n",
      "           2       0.61      0.61      0.61       365\n",
      "           3       0.82      0.77      0.79       377\n",
      "\n",
      "    accuracy                           0.71      1500\n",
      "   macro avg       0.71      0.71      0.71      1500\n",
      "weighted avg       0.71      0.71      0.71      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       116\n",
      "           1       0.47      0.52      0.49       126\n",
      "           2       0.54      0.50      0.52       135\n",
      "           3       0.75      0.67      0.71       123\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.62      0.61      0.61       500\n",
      "weighted avg       0.61      0.61      0.61       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[343  41   0   0]\n",
      " [ 97 212  62   3]\n",
      " [ 13  66 223  63]\n",
      " [  0   8  78 291]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[88 27  1  0]\n",
      " [34 66 24  2]\n",
      " [ 3 40 67 25]\n",
      " [ 0  8 32 83]]\n",
      "{'k': 15, 'acc': [0.7133333333333334, 0.606]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       384\n",
      "           1       0.64      0.56      0.60       374\n",
      "           2       0.62      0.62      0.62       365\n",
      "           3       0.81      0.78      0.80       377\n",
      "\n",
      "    accuracy                           0.71      1500\n",
      "   macro avg       0.71      0.71      0.71      1500\n",
      "weighted avg       0.71      0.71      0.71      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71       116\n",
      "           1       0.49      0.56      0.52       126\n",
      "           2       0.54      0.47      0.50       135\n",
      "           3       0.73      0.69      0.71       123\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.61      0.61      0.61       500\n",
      "weighted avg       0.61      0.61      0.61       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[339  44   1   0]\n",
      " [ 96 211  63   4]\n",
      " [ 12  64 226  63]\n",
      " [  0   9  74 294]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[84 30  2  0]\n",
      " [33 71 20  2]\n",
      " [ 5 38 63 29]\n",
      " [ 0  7 31 85]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for k in range(1,16,2):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,weights='uniform')\n",
    "    \n",
    "    knn.fit(x_train_sc,y_train)\n",
    "    \n",
    "    train_pred=knn.predict(x_train_sc)\n",
    "    test_pred=knn.predict(x_test_sc)\n",
    "    \n",
    "    tr_acc=accuracy_score(y_train,train_pred)\n",
    "    \n",
    "    ts_acc=accuracy_score(y_test,test_pred)\n",
    "    \n",
    "    accuracy=({'k':k,'acc':[tr_acc,ts_acc]})\n",
    "    print(accuracy)\n",
    "    \n",
    "    print('\\n tr_report',report(y_train,train_pred))\n",
    "    print('\\n ts_report\\n',report(y_test,test_pred))    \n",
    "    print('\\n tr_matrix\\n',matrix(y_train,train_pred))\n",
    "    print('\\nts_matrix\\n\\n ',matrix(y_test,test_pred))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8deec",
   "metadata": {},
   "source": [
    "# KNN  BASE MODEL with UNSCALED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a0ed588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': [1.0, 0.642]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       384\n",
      "           1       1.00      1.00      1.00       374\n",
      "           2       1.00      1.00      1.00       365\n",
      "           3       1.00      1.00      1.00       377\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       116\n",
      "           1       0.54      0.48      0.51       126\n",
      "           2       0.52      0.56      0.54       135\n",
      "           3       0.74      0.72      0.73       123\n",
      "\n",
      "    accuracy                           0.64       500\n",
      "   macro avg       0.65      0.65      0.65       500\n",
      "weighted avg       0.64      0.64      0.64       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[384   0   0   0]\n",
      " [  0 374   0   0]\n",
      " [  0   0 365   0]\n",
      " [  0   0   0 377]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[96 19  1  0]\n",
      " [24 61 40  1]\n",
      " [ 2 27 76 30]\n",
      " [ 0  5 30 88]]\n",
      "{'k': [0.8293333333333334, 0.68]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       384\n",
      "           1       0.76      0.78      0.77       374\n",
      "           2       0.81      0.72      0.76       365\n",
      "           3       0.89      0.90      0.90       377\n",
      "\n",
      "    accuracy                           0.83      1500\n",
      "   macro avg       0.83      0.83      0.83      1500\n",
      "weighted avg       0.83      0.83      0.83      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       116\n",
      "           1       0.59      0.56      0.58       126\n",
      "           2       0.59      0.60      0.59       135\n",
      "           3       0.79      0.76      0.77       123\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.68      0.68      0.68       500\n",
      "weighted avg       0.68      0.68      0.68       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[352  32   0   0]\n",
      " [ 54 290  30   0]\n",
      " [  4  57 261  43]\n",
      " [  0   3  33 341]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[95 20  1  0]\n",
      " [28 71 27  0]\n",
      " [ 2 28 81 24]\n",
      " [ 0  1 29 93]]\n",
      "{'k': [0.8046666666666666, 0.708]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       384\n",
      "           1       0.73      0.73      0.73       374\n",
      "           2       0.76      0.70      0.73       365\n",
      "           3       0.87      0.89      0.88       377\n",
      "\n",
      "    accuracy                           0.80      1500\n",
      "   macro avg       0.80      0.80      0.80      1500\n",
      "weighted avg       0.80      0.80      0.80      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       116\n",
      "           1       0.63      0.61      0.62       126\n",
      "           2       0.61      0.61      0.61       135\n",
      "           3       0.82      0.79      0.80       123\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.71      0.71      0.71       500\n",
      "weighted avg       0.71      0.71      0.71       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[345  39   0   0]\n",
      " [ 60 272  42   0]\n",
      " [  3  58 255  49]\n",
      " [  0   2  40 335]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[97 19  0  0]\n",
      " [22 77 27  0]\n",
      " [ 3 27 83 22]\n",
      " [ 0  0 26 97]]\n",
      "{'k': [0.7913333333333333, 0.708]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       384\n",
      "           1       0.72      0.73      0.73       374\n",
      "           2       0.72      0.67      0.70       365\n",
      "           3       0.86      0.86      0.86       377\n",
      "\n",
      "    accuracy                           0.79      1500\n",
      "   macro avg       0.79      0.79      0.79      1500\n",
      "weighted avg       0.79      0.79      0.79      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       116\n",
      "           1       0.61      0.60      0.60       126\n",
      "           2       0.61      0.63      0.62       135\n",
      "           3       0.83      0.78      0.80       123\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.71      0.71      0.71       500\n",
      "weighted avg       0.71      0.71      0.71       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[344  40   0   0]\n",
      " [ 57 272  45   0]\n",
      " [  3  62 245  55]\n",
      " [  0   2  49 326]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[98 18  0  0]\n",
      " [23 75 28  0]\n",
      " [ 2 28 85 20]\n",
      " [ 0  1 26 96]]\n",
      "{'k': [0.7873333333333333, 0.702]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       384\n",
      "           1       0.73      0.70      0.71       374\n",
      "           2       0.70      0.68      0.69       365\n",
      "           3       0.85      0.86      0.86       377\n",
      "\n",
      "    accuracy                           0.79      1500\n",
      "   macro avg       0.78      0.79      0.78      1500\n",
      "weighted avg       0.79      0.79      0.79      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       116\n",
      "           1       0.62      0.58      0.60       126\n",
      "           2       0.60      0.62      0.61       135\n",
      "           3       0.81      0.78      0.80       123\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.71      0.71      0.71       500\n",
      "weighted avg       0.70      0.70      0.70       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[345  39   0   0]\n",
      " [ 57 263  54   0]\n",
      " [  3  58 248  56]\n",
      " [  0   2  50 325]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[98 18  0  0]\n",
      " [23 73 30  0]\n",
      " [ 2 27 84 22]\n",
      " [ 0  0 27 96]]\n",
      "{'k': [0.7806666666666666, 0.714]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       384\n",
      "           1       0.72      0.70      0.71       374\n",
      "           2       0.69      0.66      0.68       365\n",
      "           3       0.85      0.86      0.85       377\n",
      "\n",
      "    accuracy                           0.78      1500\n",
      "   macro avg       0.78      0.78      0.78      1500\n",
      "weighted avg       0.78      0.78      0.78      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       116\n",
      "           1       0.63      0.61      0.62       126\n",
      "           2       0.62      0.64      0.63       135\n",
      "           3       0.82      0.80      0.81       123\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.72      0.72      0.72       500\n",
      "weighted avg       0.71      0.71      0.71       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[343  41   0   0]\n",
      " [ 56 262  56   0]\n",
      " [  3  63 242  57]\n",
      " [  0   0  53 324]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[96 20  0  0]\n",
      " [22 77 27  0]\n",
      " [ 1 26 86 22]\n",
      " [ 0  0 25 98]]\n",
      "{'k': [0.7773333333333333, 0.708]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       384\n",
      "           1       0.71      0.68      0.70       374\n",
      "           2       0.69      0.65      0.67       365\n",
      "           3       0.85      0.86      0.86       377\n",
      "\n",
      "    accuracy                           0.78      1500\n",
      "   macro avg       0.77      0.78      0.77      1500\n",
      "weighted avg       0.77      0.78      0.78      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       116\n",
      "           1       0.62      0.58      0.60       126\n",
      "           2       0.63      0.64      0.64       135\n",
      "           3       0.82      0.80      0.81       123\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.71      0.71      0.71       500\n",
      "weighted avg       0.71      0.71      0.71       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[345  39   0   0]\n",
      " [ 61 256  57   0]\n",
      " [  3  65 239  58]\n",
      " [  0   0  51 326]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[96 20  0  0]\n",
      " [27 73 26  0]\n",
      " [ 1 25 87 22]\n",
      " [ 0  0 25 98]]\n",
      "{'k': [0.7746666666666666, 0.7]}\n",
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       384\n",
      "           1       0.71      0.68      0.69       374\n",
      "           2       0.69      0.65      0.67       365\n",
      "           3       0.85      0.87      0.86       377\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.77      0.77      0.77      1500\n",
      "weighted avg       0.77      0.77      0.77      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       116\n",
      "           1       0.60      0.58      0.59       126\n",
      "           2       0.62      0.63      0.63       135\n",
      "           3       0.80      0.80      0.80       123\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.70      0.70      0.70       500\n",
      "weighted avg       0.70      0.70      0.70       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[344  40   0   0]\n",
      " [ 63 253  58   0]\n",
      " [  3  65 237  60]\n",
      " [  0   0  49 328]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[93 23  0  0]\n",
      " [26 73 27  0]\n",
      " [ 1 25 85 24]\n",
      " [ 0  0 24 99]]\n"
     ]
    }
   ],
   "source": [
    "# model fitting without scaling with different k values\n",
    "\n",
    "for k in range(1,16,2):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,weights='uniform')\n",
    "    \n",
    "    knn.fit(x_train,y_train)\n",
    "    \n",
    "    train_pred=knn.predict(x_train)\n",
    "    test_pred=knn.predict(x_test)\n",
    "    \n",
    "    tr_acc=accuracy_score(y_train,train_pred)\n",
    "    \n",
    "    ts_acc=accuracy_score(y_test,test_pred)\n",
    "    \n",
    "    accuracy=({'k':[tr_acc,ts_acc]})\n",
    "    print(accuracy)\n",
    "    \n",
    "    print('\\n tr_report',report(y_train,train_pred))\n",
    "    print('\\n ts_report\\n',report(y_test,test_pred))    \n",
    "    print('\\n tr_matrix\\n',matrix(y_train,train_pred))\n",
    "    print('\\nts_matrix\\n\\n ',matrix(y_test,test_pred))\n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307b2f2",
   "metadata": {},
   "source": [
    "# KNN model with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fc89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "145856b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tr_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       384\n",
      "           1       0.71      0.68      0.69       374\n",
      "           2       0.69      0.65      0.67       365\n",
      "           3       0.85      0.87      0.86       377\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.77      0.77      0.77      1500\n",
      "weighted avg       0.77      0.77      0.77      1500\n",
      "\n",
      "\n",
      " ts_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       116\n",
      "           1       0.60      0.58      0.59       126\n",
      "           2       0.62      0.63      0.63       135\n",
      "           3       0.80      0.80      0.80       123\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.70      0.70      0.70       500\n",
      "weighted avg       0.70      0.70      0.70       500\n",
      "\n",
      "\n",
      " tr_matrix\n",
      " [[344  40   0   0]\n",
      " [ 63 253  58   0]\n",
      " [  3  65 237  60]\n",
      " [  0   0  49 328]]\n",
      "\n",
      "ts_matrix\n",
      "\n",
      "  [[93 23  0  0]\n",
      " [26 73 27  0]\n",
      " [ 1 25 85 24]\n",
      " [ 0  0 24 99]]\n"
     ]
    }
   ],
   "source": [
    "# RFE setting\n",
    "rfe =RFE(estimator =knn,n_features_to_select =10,step=3,verbose =1)\n",
    "rfe.fit(x_train,y_train)\n",
    "\n",
    "train_pred=rfe.predict(x_train)\n",
    "test_pred=knn.predict(x_test)\n",
    "\n",
    "print('\\n tr_report',report(y_train,train_pred))\n",
    "print('\\n ts_report\\n',report(y_test,test_pred))    \n",
    "print('\\n tr_matrix\\n',matrix(y_train,train_pred))\n",
    "print('\\nts_matrix\\n\\n ',matrix(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244d4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
