{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"NQDOHSLOfEhm","executionInfo":{"status":"ok","timestamp":1645081376415,"user_tz":-330,"elapsed":53270,"user":{"displayName":"Prasad K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVE6Y0fcvEiEg1Xv0vSXf40nSQo-RX7Dg4NrzaA=s64","userId":"14994654495791802840"}},"outputId":"1ae76f01-f8a4-4d13-a6e2-f507ea70888d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 33.7 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=012e849825e248fb5e751c345ac752a35820cd8a049aa8ceb621ff583630438c\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}],"source":["!pip install pyspark\n","import pyspark\n","\n","\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"id":"nTKVdtF5fEhu","executionInfo":{"status":"ok","timestamp":1645081384112,"user_tz":-330,"elapsed":7717,"user":{"displayName":"Prasad K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVE6Y0fcvEiEg1Xv0vSXf40nSQo-RX7Dg4NrzaA=s64","userId":"14994654495791802840"}}},"outputs":[],"source":["sc = SparkContext(conf=SparkConf())\n","spark = SparkSession(sparkContext=sc)"]},{"cell_type":"markdown","metadata":{"id":"b0oUxjM5fEhv"},"source":["# Example data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phf2Td4ffEhx","outputId":"3b4a5f1c-d35f-4a40-d602-d7031b0fe9f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------+---+---+---+---+\n","| x1|    x2| x3| x4| y1| y2|\n","+---+------+---+---+---+---+\n","|  a| apple|  1|2.4|  1|yes|\n","|  a|orange|  1|2.5|  0| no|\n","|  b|orange|  2|3.5|  1| no|\n","|  b|orange|  2|1.4|  0|yes|\n","|  b| peach|  2|2.1|  0|yes|\n","|  c| peach|  4|1.5|  1|yes|\n","+---+------+---+---+---+---+\n","\n"]}],"source":["import pandas as pd\n","pdf = pd.DataFrame({\n","        'x1': ['a','a','b','b', 'b', 'c'],\n","        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n","        'x3': [1, 1, 2, 2, 2, 4],\n","        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n","        'y1': [1, 0, 1, 0, 0, 1],\n","        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n","    })\n","df = spark.createDataFrame(pdf)\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"QXbVTalVfEh1"},"source":["# StringIndexer"]},{"cell_type":"markdown","metadata":{"id":"cZJj1CjYfEh2"},"source":["`StringIndexer` maps a string column to a index column that will be treated as a categorical column by spark. **The indices start with 0 and are ordered by label frequencies**. If it is a numerical column, the column will first be casted to a string column and then indexed by  StringIndexer.\n","\n","There are three steps to implement the StringIndexer\n","\n","1. Build the StringIndexer model: specify the input column and output column names.\n","2. Learn the StringIndexer model: fit the model with your data.\n","3. Execute the indexing: call the transform function to execute the indexing process."]},{"cell_type":"markdown","metadata":{"id":"6lbrWD81fEh3"},"source":["### Example: `StringIndex` column \"x1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dvsrc0eTfEh4","outputId":"3b72e718-06e9-4921-9880-e436cf8fee75"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------+---+---+---+---+----------+\n","| x1|    x2| x3| x4| y1| y2|indexed_x1|\n","+---+------+---+---+---+---+----------+\n","|  a| apple|  1|2.4|  1|yes|       1.0|\n","|  a|orange|  1|2.5|  0| no|       1.0|\n","|  b|orange|  2|3.5|  1| no|       0.0|\n","|  b|orange|  2|1.4|  0|yes|       0.0|\n","|  b| peach|  2|2.1|  0|yes|       0.0|\n","|  c| peach|  4|1.5|  1|yes|       2.0|\n","+---+------+---+---+---+---+----------+\n","\n"]}],"source":["from pyspark.ml.feature import StringIndexer\n","\n","# build indexer\n","string_indexer = StringIndexer(inputCol='x1', outputCol='indexed_x1')\n","\n","# learn the model\n","string_indexer_model = string_indexer.fit(df)\n","\n","# transform the data\n","df_stringindexer = string_indexer_model.transform(df)\n","\n","# resulting df\n","df_stringindexer.show()"]},{"cell_type":"markdown","metadata":{"id":"gBM6dWEyfEh5"},"source":["From the result above, we can see that (a, b, c) in column x1 are converted to (1.0, 0.0, 2.0). They are ordered by their frequencies in column x1.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ViVwOetvfEh6"},"source":["# OneHotEncoder"]},{"cell_type":"markdown","metadata":{"id":"o51izk1VfEh6"},"source":["**`OneHotEncoder`** converts each categories of a **StringIndexed** column to a `sparse vector`. Each sparse vector has **at most one single active elements** that indicate the category index."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbQv5KfcfEh7","outputId":"a3888991-3262-43e2-bab8-a3a9c6f4e192"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+\n","| x1|\n","+---+\n","|  a|\n","|  a|\n","|  b|\n","|  b|\n","|  b|\n","|  c|\n","+---+\n","\n"]}],"source":["df_ohe = df.select('x1')\n","df_ohe.show()"]},{"cell_type":"markdown","metadata":{"id":"s80ehV9WfEh7"},"source":["### `StringIndex` column 'x1'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIBkArSVfEh8","outputId":"51c69e3e-e06e-4a2e-d8a0-c308d0c8b208"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+\n","| x1|indexed_x1|\n","+---+----------+\n","|  a|       1.0|\n","|  a|       1.0|\n","|  b|       0.0|\n","|  b|       0.0|\n","|  b|       0.0|\n","|  c|       2.0|\n","+---+----------+\n","\n"]}],"source":["df_x1_indexed = StringIndexer(inputCol='x1', outputCol='indexed_x1').fit(df_ohe).transform(df_ohe)\n","df_x1_indexed.show()"]},{"cell_type":"markdown","metadata":{"id":"MoGZgHMpfEh8"},"source":["'x1' has three categories: 'a', 'b' and 'c',  which corresponding string indices 1.0, 0.0 and 2.0, respectively."]},{"cell_type":"markdown","metadata":{"id":"99Uj6p2efEh8"},"source":["### Mapping string indices to sparse vectors"]},{"cell_type":"markdown","metadata":{"id":"H3vofd1LfEh9"},"source":["* Encoding format: 'string index': ['string indices vector size', 'index of string index in string indices vector', **1.0** ]"]},{"cell_type":"markdown","metadata":{"id":"L1kO79n-fEh9"},"source":["Here the string indices vector is `[0.0, 1.0, 2.0]`. Therefore, the mapping between string indices and sparse vectors are:\n","* `0.0: [3, [0], [1.0]]`\n","* `1.0: [3, [1], [1.0]]`\n","* `2.0: [3, [2], [1.0]]`"]},{"cell_type":"markdown","metadata":{"id":"RCet0jyIfEh9"},"source":["After we convert all sparse vectors to dense vectors, we get:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PiaZ6s3zfEh-","outputId":"f51bba2b-0ef8-4170-cb4e-75d0cc655c4e"},"outputs":[{"data":{"text/plain":["array([[ 1.,  0.,  0.],\n","       [ 0.,  1.,  0.],\n","       [ 0.,  0.,  1.]])"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.ml.linalg import DenseVector, SparseVector, DenseMatrix, SparseMatrix\n","x = [SparseVector(3, {0: 1.0}).toArray()] + \\\n","    [SparseVector(3, {1: 1.0}).toArray()] + \\\n","    [SparseVector(3, {2: 1.0}).toArray()]\n","\n","import numpy as np\n","np.array(x)"]},{"cell_type":"markdown","metadata":{"id":"zHxTXv2WfEh_"},"source":["**The obtained matrix is exactly the matrix that we would use to represent our categorical variable in a statistical class**."]},{"cell_type":"markdown","metadata":{"id":"GNcg_F1VfEh_"},"source":["### One more step to go\n","\n","`OneHotEncoder` by default will drop the last category. So the **string indices vector** becomes `[0.0, 1.0]`, and the mappings between string indices and sparse vectors are:\n","\n","* `0.0: [2, [0], [1.0]]`\n","* `1.0: [2, [1], [1.0]]`\n","* `2.0: [2, [], []]`\n","\n","We use a sparse vector that has **no active element**(basically all elements are 0's) to represent the last category."]},{"cell_type":"markdown","metadata":{"id":"rakb8Gm9fEh_"},"source":["# Verify"]},{"cell_type":"markdown","metadata":{"id":"Jmhm78dafEiA"},"source":["### OneHotEncode column 'indexed_x1'"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"TXiTBHpWfEiA"},"outputs":[],"source":["from pyspark.ml.feature import OneHotEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRjrUvCPfEiA","outputId":"b480f512-dffe-488c-c2ba-203156599db4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+-------------+\n","| x1|indexed_x1|   encoded_x1|\n","+---+----------+-------------+\n","|  a|       1.0|(2,[1],[1.0])|\n","|  a|       1.0|(2,[1],[1.0])|\n","|  b|       0.0|(2,[0],[1.0])|\n","|  b|       0.0|(2,[0],[1.0])|\n","|  b|       0.0|(2,[0],[1.0])|\n","|  c|       2.0|    (2,[],[])|\n","+---+----------+-------------+\n","\n"]}],"source":["OneHotEncoder(inputCol='indexed_x1', outputCol='encoded_x1').transform(df_x1_indexed).show()"]},{"cell_type":"markdown","metadata":{"id":"fPbS0clPfEiA"},"source":["### Specify to not drop the last category\n","\n","If we choose to not drop the last category, we get the expected results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-XspKi1fEiB","outputId":"0e282736-ab31-4181-f6a5-0c44e3f19925"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+-------------+\n","| x1|indexed_x1|   encoded_x1|\n","+---+----------+-------------+\n","|  a|       1.0|(3,[1],[1.0])|\n","|  a|       1.0|(3,[1],[1.0])|\n","|  b|       0.0|(3,[0],[1.0])|\n","|  b|       0.0|(3,[0],[1.0])|\n","|  b|       0.0|(3,[0],[1.0])|\n","|  c|       2.0|(3,[2],[1.0])|\n","+---+----------+-------------+\n","\n"]}],"source":["OneHotEncoder(dropLast=False, inputCol='indexed_x1', outputCol='encoded_x1').transform(df_x1_indexed).show()"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.0"},"colab":{"name":"stringindexer-and-onehotencoder.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}