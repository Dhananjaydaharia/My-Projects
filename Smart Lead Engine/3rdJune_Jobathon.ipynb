{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f1282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477060e",
   "metadata": {},
   "source": [
    "Smart Lead Scoring Engine\n",
    "\n",
    "\n",
    "Can you identify the potential leads for a D2C startup?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Problem Statement\n",
    "\n",
    "\n",
    "A D2C startup develops products using cutting edge technologies like Web 3.0. Over the past few months, the company has started multiple marketing campaigns offline and digital both. As a result, the users have started showing interest in the product on the website. These users with intent to buy product(s) are generally known as leads (Potential Customers). \n",
    "\n",
    "\n",
    "Leads are captured in 2 ways - Directly and Indirectly. \n",
    "\n",
    "\n",
    "Direct leads are captured via forms embedded in the website while indirect leads are captured based on certain activity of a user on the platform such as time spent on the website, number of user sessions, etc.\n",
    "\n",
    "\n",
    "Now, the marketing & sales team wants to identify the leads who are more likely to buy the product so that the sales team can manage their bandwidth efficiently by targeting these potential leads and increase the sales in a shorter span of time.\n",
    "\n",
    "\n",
    "Now, as a data scientist, your task at hand is to predict the propensity to buy a product based on the user's past activities and user level information.\n",
    "\n",
    "\n",
    "\n",
    "About Dataset\n",
    "\n",
    "\n",
    "You are provided with the leads data of last year containing both direct and indirect leads. Each lead provides information about their activity on the platform, signup information and campaign information. Based on his past activity on the platform, you need to build the predictive model to classify if the user would buy the product in the next 3 months or not.\n",
    "\n",
    "\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "\n",
    "You are provided with 3 files - train.csv, test.csv and sample_submission.csv\n",
    "\n",
    "\n",
    "\n",
    "Training set\n",
    "\n",
    "\n",
    "train.csv contains the leads information of last 1 year from Jan 2021 to Dec 2021. And also the target variable indicating if the user will buy the product in next 3 months or not \n",
    "\n",
    "\n",
    "\n",
    "Variable\n",
    "\n",
    "Description\n",
    "\n",
    "id\n",
    "\n",
    "Unique identifier of a lead\n",
    "\n",
    "created_at\n",
    "\n",
    "Date of lead dropped\n",
    "\n",
    "signup_date\n",
    "\n",
    "Sign up date of the user on the website\n",
    "\n",
    "campaign_var (1 and 2)\n",
    "\n",
    "campaign information of the lead\n",
    "\n",
    "products_purchased\n",
    "\n",
    "No. of past products purchased at the time of dropping the lead\n",
    "\n",
    "user_activity_var (1 to 12)\n",
    "\n",
    "Derived activities of the user on the website\n",
    "\n",
    "buy\n",
    "\n",
    "0 or 1 indicating if the user will buy the product in next 3 months or not \n",
    "\n",
    "\n",
    "\n",
    "Test set\n",
    "\n",
    "\n",
    "test.csv contains the leads information of the current year from Jan 2022 to March 2022. You need to predict if the lead will buy the product in next 3 months or not.\n",
    "\n",
    "\n",
    "\n",
    "Variable\n",
    "\n",
    "Description\n",
    "\n",
    "id\n",
    "\n",
    "Unique identifier of a lead\n",
    "\n",
    "created_at\n",
    "\n",
    "Date of lead dropped\n",
    "\n",
    "signup_date\n",
    "\n",
    "Sign up date of the user on the website\n",
    "\n",
    "campaign_var (1 and 2)\n",
    "\n",
    "Campaign information of the lead\n",
    "\n",
    "products_purchased\n",
    "\n",
    "No. of past products purchased at the time of dropping the lead\n",
    "\n",
    "user_activity_var (1 to 12) \n",
    "\n",
    "Derived activities of the user on the website\n",
    "\n",
    "\n",
    "\n",
    "Submission File Format\n",
    "\n",
    "\n",
    "sample_submission.csv contains 2 variables - \n",
    "\n",
    "\n",
    "\n",
    "Variable\n",
    "\n",
    "Description\n",
    "\n",
    "id\n",
    "\n",
    "Unique Identifier of a lead\n",
    "\n",
    "buy\n",
    "\n",
    "0 or 1 indicating if the user will buy the product in next 3 months or not\n",
    "\n",
    "\n",
    "\n",
    "Evaluation metric\n",
    "\n",
    "\n",
    "The evaluation metric for this hackathon would be F1 Score of Class 1.\n",
    "\n",
    "\n",
    "\n",
    "Public and Private Split\n",
    "\n",
    "\n",
    "Test data is further divided into Public (40%) and Private (60%) data. \n",
    "\n",
    "\n",
    "Your initial responses will be checked and scored on the Public data. The final rankings would be based on your private score which will be published once the competition is over.\n",
    "\n",
    "\n",
    "\n",
    "Submission Tutorials\n",
    "\n",
    "\n",
    "All Submissions are to be done at the solution checker tab.\n",
    "For a step by step view on how to make a submission check the below video\n",
    "\n",
    "\n",
    "\n",
    "Guidelines for Final Submission\n",
    "\n",
    "\n",
    "Please ensure that your final submission includes the following:\n",
    "\n",
    "Solution file containing the predictions for the id in the test set (Format is given in sample_submission.csv)\n",
    "A zipped file containing code & approach (Note that both code and approach document are mandatory for shortlisting)\n",
    "Code: Clean code with comments on each part\n",
    "Approach: Please share your approach to solve the problem (doc/ppt/pdf format). It should cover the following topics:\n",
    "A brief on the approach used to solve the problem.\n",
    "Which Data-preprocessing / Feature Engineering ideas really worked? How did you discover them?\n",
    "What does your final model look like? How did you reach it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c168f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.6-cp39-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dhananjay\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "def models(x, y):\n",
    "    accuracy = []\n",
    "    f1score = []\n",
    "    model = []\n",
    "    \n",
    "    model.append(LogisticRegression())\n",
    "    model.append(KNeighborsClassifier())\n",
    "    model.append(SVC(random_state=40))\n",
    "    model.append(RandomForestClassifier(random_state=40))\n",
    "    model.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=40)))\n",
    "    model.append(BaggingClassifier(random_state=40))\n",
    "    model.append(GradientBoostingClassifier(random_state=40))\n",
    "    model.append(XGBClassifier(random_state=40, verbosity=0))\n",
    "    model.append(CatBoostClassifier(random_state=40, verbose=0))\n",
    "    \n",
    "    for i in model:\n",
    "        mdl = i\n",
    "        i.fit(x_train_sc, y_train)\n",
    "        pred = i.predict(x_test_sc)\n",
    "        \n",
    "        accuracy.append((round(accuracy_score(y_test, test_pred), 2))*100)\n",
    "        f1score.append((round(f1_score(y_test, test_pred), 2))*100)\n",
    "        \n",
    "        print(f'Model: {i}\\nAccuracy: {accuracy_score(y_test, test_pred)}\\nF1-score: {f1_score(y_test, test_pred)}\\n\\n')\n",
    "   \n",
    "\n",
    " models(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4ad57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(model,x,y):\n",
    "    \n",
    "    tuned_paramaters = [{'criterion': ['gini', 'entropy'],\n",
    "                     'min_samples_split': [10, 20, 30],\n",
    "                     'max_depth': [3, 5, 7, 9],\n",
    "                     'min_samples_leaf': [15, 20, 25, 30, 35],\n",
    "                     'max_leaf_nodes': [5, 10, 15, 20, 25],\n",
    "                     'n_estimators':[100,150,200]}]\n",
    "    grid = GridSearchCV(estimator = model, \n",
    "                         param_grid = tuned_paramaters, \n",
    "                         cv = 10)\n",
    "    \n",
    "    gridModel=grid.fit(x,y)\n",
    "    \n",
    "    return gridModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4903c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(x,y):\n",
    "    accuracy=[]\n",
    "    f1score=[]\n",
    "    models=[]\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(SVC(random_state=40))\n",
    "    models.append(RandomForestClassifier(random_state=40))\n",
    "    models.append(GradientBoostingClassifier(random_state=40))\n",
    "    models.append(XGBClassifier(random_state=40, verbosity=0))\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(GaussianNB())\n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        print(type(model))\n",
    "       \n",
    "        \n",
    "        if str(model) == 'DecisionTreeClassifier()' or str(model)== 'RandomForestClassifier(random_state=40)':\n",
    "            \n",
    "            \n",
    "            \n",
    "            bestParams=getBestParams(model,x,y)\n",
    "            \n",
    "            print(bestParams.best_params_)\n",
    "            gridModel=model(\n",
    "                \n",
    "                criterion=bestParams.best_params_.get('criterion'),\n",
    "                max_depth=bestParams.best_params_.get('max_depth'),\n",
    "                max_leaf_nodes=bestParams.best_params_.get('max_leaf_nodes'),\n",
    "                min_samples_leaf=bestParams.best_params_.get('min_samples_leaf'),\n",
    "                min_samples_split=bestParams.best_params_.get('min_samples_split'),\n",
    "                n_estimators=bestParams.best_params_.get('n_estimators')\n",
    "            )\n",
    "            \n",
    "            gridModel.fit(x,y)\n",
    "            test_pred=gridModel.predict(x_test_sc)\n",
    "        \n",
    "        else:\n",
    "            model.fit(x,y)\n",
    "            test_pred=model.predict(x_test_sc)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f'Model: {model}\\n')\n",
    "        \n",
    "        print('\\n Classification Report : \\n ')\n",
    "        \n",
    "        print(classification_report(y_test, test_pred))\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "        print(f'Model: {model}\\nAccuracy: {accuracy_score(y_test, test_pred)}\\nF1-score: {f1_score(y_test, test_pred)}\\n\\n')\n",
    "\n",
    "\n",
    "# Model Building        \n",
    "BuildModel(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(model,x,y):\n",
    "    \n",
    "    tuned_paramaters = [{'max_depth':[5,10,15,20,30],'min_samples_split':[10,20,25,40,60,100],'n_estimators':[100,150,200]}]\n",
    "    grid = GridSearchCV(estimator = model, \n",
    "                         param_grid = tuned_paramaters, \n",
    "                         cv = 6)\n",
    "    \n",
    "    gridModel=grid.fit(x,y)\n",
    "    \n",
    "    return gridModelb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(x,y):\n",
    "    accuracy=[]\n",
    "    f1score=[]\n",
    "    models=[]\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(SVC(random_state=40))\n",
    "    models.append(RandomForestClassifier(random_state=40))\n",
    "    models.append(GradientBoostingClassifier(random_state=40))\n",
    "    models.append(XGBClassifier(random_state=40, verbosity=0))\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(GaussianNB())\n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        \n",
    "        modelName=str(model)\n",
    "        print(type(model),type(modelName))\n",
    "       \n",
    "        \n",
    "        if modelName == 'DecisionTreeClassifier()' or modelName == 'RandomForestClassifier(random_state=40)':\n",
    "            \n",
    "            \n",
    "            \n",
    "            bestParams=getBestParams(model,x,y)\n",
    "            \n",
    "            print(bestParams.best_params_)\n",
    "            gridModel=model(\n",
    "                \n",
    "                \n",
    "                max_depth=bestParams.best_params_.get('max_depth'),\n",
    "                min_samples_split=bestParams.best_params_.get('min_samples_split'),\n",
    "                n_estimators=bestParams.best_params_.get('n_estimators')\n",
    "            )\n",
    "            \n",
    "            gridModel.fit(x,y)\n",
    "            test_pred=gridModel.predict(x_test_sc)\n",
    "        \n",
    "        else:\n",
    "            model.fit(x,y)\n",
    "            test_pred=model.predict(x_test_sc)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f'Model: {model}\\n')\n",
    "        \n",
    "        print('\\n Classification Report : \\n ')\n",
    "        \n",
    "        print(classification_report(y_test, test_pred))\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "        print(f'Model: {model}\\nAccuracy: {accuracy_score(y_test, test_pred)}\\nF1-score: {f1_score(y_test, test_pred)}\\n\\n')\n",
    "\n",
    "\n",
    "# Model Building        \n",
    "BuildModel(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1st run\n",
    "Model                 \tPrecision Score\t Recall Score\tAccuracy Score\tf1-score\n",
    "0\tLogistic Regression\t            0.808018\t0.747802\t0.784254\t0.776744\n",
    "1\tRandom Forest Best Estimator\t0.879615\t0.911967\t0.893176\t0.895499\n",
    "2\tXGBoost MOdel Best Estimator\t0.879816\t0.923118\t0.898127\t0.900947\n",
    "3\tDeep Neural Network          \t0.866594\t0.853957\t0.860725\t0.860229\n",
    "\n",
    "2nd run\n",
    "\n",
    "\tModel\t                 Precision Score\tRecall Score\tAccuracy Score\tf1-score\n",
    "0\tLogistic Regression\t             0.80728\t0.742012\t0.781617\t0.773271\n",
    "1\tRandom Forest Best Estimator\t0.877193\t0.906069\t0.889194\t0.891397\n",
    "2\tRandom Forest Best Estimator\t0.879554\t0.905962\t0.890539\t0.892563\n",
    "3\tRandom Forest Best Estimator\t0.877461\t0.917542\t0.894306\t0.897054\n",
    "4\tXGBoost MOdel Best Estimator\t0.881333\t0.915827\t0.895867\t0.898249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results wanted\n",
    "\n",
    "\n",
    "Model\t                         Precision Score\tRecall Score\tAccuracy Score\tf1-score\n",
    "0\tLogistic Regression             0.792072\t    0.829187\t       0.805026\t    0.810205\n",
    "1\tDecision Tree Base\t            0.906736\t    0.94971\t           0.925735\t    0.927726\n",
    "2\tRandom Forest Base\t            0.916614\t    0.940596\t       0.927241\t    0.92845\n",
    "3\tRandom Forest Base\t            0.885047\t    0.922153\t       0.900818 \t0.903219\n",
    "4\tRandom Forest Base\t            0.916614\t    0.940596\t       0.927241 \t0.92845\n",
    "5\tLogistic Regression\t            0.738056\t    0.813318\t       0.761436 \t0.773861\n",
    "6\tDecision Tree Base\t            0.881179\t    0.932769\t       0.903132\t    0.90624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5116ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
